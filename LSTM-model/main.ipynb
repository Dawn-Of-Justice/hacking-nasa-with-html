{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the InceptionBlock and InceptionLSTMMoonquake classes as provided\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=5, padding=2)\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "        b3 = self.branch3(x)\n",
    "        b4 = self.branch4(x)\n",
    "        return torch.cat([b1, b2, b3, b4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionLSTMMoonquake(nn.Module):\n",
    "    def __init__(self, sequence_length=1000, num_classes=1):\n",
    "        super(InceptionLSTMMoonquake, self).__init__()\n",
    "        \n",
    "        self.inception1 = InceptionBlock(1, 32)\n",
    "        self.inception2 = InceptionBlock(128, 32)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset class\n",
    "class MoonquakeDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = torch.FloatTensor(signals)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.signals[idx], self.labels[idx]\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for signals, labels in train_loader:\n",
    "            signals, labels = signals.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                signals, labels = signals.to(device), labels.to(device)\n",
    "                outputs = model(signals)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        logger.info(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        logger.info(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for signals, labels in test_loader:\n",
    "            signals, labels = signals.to(device), labels.to(device)\n",
    "            outputs = model(signals)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Inference function for deployment\n",
    "def inference(model, signal, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        signal = torch.FloatTensor(signal).unsqueeze(0).to(device)\n",
    "        output = model(signal)\n",
    "        is_quake = output.item() > 0.5\n",
    "    return is_quake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Epoch 1/50:\n",
      "INFO:__main__:Train Loss: 0.6944, Val Loss: 0.6965\n",
      "INFO:__main__:Epoch 2/50:\n",
      "INFO:__main__:Train Loss: 0.6937, Val Loss: 0.6978\n",
      "INFO:__main__:Epoch 3/50:\n",
      "INFO:__main__:Train Loss: 0.6907, Val Loss: 0.7007\n",
      "INFO:__main__:Epoch 4/50:\n",
      "INFO:__main__:Train Loss: 0.6906, Val Loss: 0.6891\n",
      "INFO:__main__:Epoch 5/50:\n",
      "INFO:__main__:Train Loss: 0.6938, Val Loss: 0.6949\n",
      "INFO:__main__:Epoch 6/50:\n",
      "INFO:__main__:Train Loss: 0.6891, Val Loss: 0.7045\n",
      "INFO:__main__:Epoch 7/50:\n",
      "INFO:__main__:Train Loss: 0.6895, Val Loss: 0.7023\n",
      "INFO:__main__:Epoch 8/50:\n",
      "INFO:__main__:Train Loss: 0.6867, Val Loss: 0.7015\n",
      "INFO:__main__:Epoch 9/50:\n",
      "INFO:__main__:Train Loss: 0.6868, Val Loss: 0.7102\n",
      "INFO:__main__:Epoch 10/50:\n",
      "INFO:__main__:Train Loss: 0.6890, Val Loss: 0.6994\n",
      "INFO:__main__:Epoch 11/50:\n",
      "INFO:__main__:Train Loss: 0.6845, Val Loss: 0.7115\n",
      "INFO:__main__:Epoch 12/50:\n",
      "INFO:__main__:Train Loss: 0.6805, Val Loss: 0.7062\n",
      "INFO:__main__:Epoch 13/50:\n",
      "INFO:__main__:Train Loss: 0.6836, Val Loss: 0.7013\n",
      "INFO:__main__:Epoch 14/50:\n",
      "INFO:__main__:Train Loss: 0.6771, Val Loss: 0.6997\n",
      "INFO:__main__:Epoch 15/50:\n",
      "INFO:__main__:Train Loss: 0.6751, Val Loss: 0.7082\n",
      "INFO:__main__:Epoch 16/50:\n",
      "INFO:__main__:Train Loss: 0.6801, Val Loss: 0.7219\n",
      "INFO:__main__:Epoch 17/50:\n",
      "INFO:__main__:Train Loss: 0.6779, Val Loss: 0.6982\n",
      "INFO:__main__:Epoch 18/50:\n",
      "INFO:__main__:Train Loss: 0.6753, Val Loss: 0.7140\n",
      "INFO:__main__:Epoch 19/50:\n",
      "INFO:__main__:Train Loss: 0.6650, Val Loss: 0.7089\n",
      "INFO:__main__:Epoch 20/50:\n",
      "INFO:__main__:Train Loss: 0.6588, Val Loss: 0.7007\n",
      "INFO:__main__:Epoch 21/50:\n",
      "INFO:__main__:Train Loss: 0.6553, Val Loss: 0.7381\n",
      "INFO:__main__:Epoch 22/50:\n",
      "INFO:__main__:Train Loss: 0.6388, Val Loss: 0.7479\n",
      "INFO:__main__:Epoch 23/50:\n",
      "INFO:__main__:Train Loss: 0.6143, Val Loss: 0.7310\n",
      "INFO:__main__:Epoch 24/50:\n",
      "INFO:__main__:Train Loss: 0.6148, Val Loss: 0.8020\n",
      "INFO:__main__:Epoch 25/50:\n",
      "INFO:__main__:Train Loss: 0.5914, Val Loss: 0.7955\n",
      "INFO:__main__:Epoch 26/50:\n",
      "INFO:__main__:Train Loss: 0.5934, Val Loss: 0.7659\n",
      "INFO:__main__:Epoch 27/50:\n",
      "INFO:__main__:Train Loss: 0.5743, Val Loss: 0.8400\n",
      "INFO:__main__:Epoch 28/50:\n",
      "INFO:__main__:Train Loss: 0.5338, Val Loss: 0.8358\n",
      "INFO:__main__:Epoch 29/50:\n",
      "INFO:__main__:Train Loss: 0.5277, Val Loss: 0.8755\n",
      "INFO:__main__:Epoch 30/50:\n",
      "INFO:__main__:Train Loss: 0.4858, Val Loss: 0.9484\n",
      "INFO:__main__:Epoch 31/50:\n",
      "INFO:__main__:Train Loss: 0.4664, Val Loss: 0.9558\n",
      "INFO:__main__:Epoch 32/50:\n",
      "INFO:__main__:Train Loss: 0.4750, Val Loss: 0.8727\n",
      "INFO:__main__:Epoch 33/50:\n",
      "INFO:__main__:Train Loss: 0.3803, Val Loss: 1.0284\n",
      "INFO:__main__:Epoch 34/50:\n",
      "INFO:__main__:Train Loss: 0.4054, Val Loss: 1.0103\n",
      "INFO:__main__:Epoch 35/50:\n",
      "INFO:__main__:Train Loss: 0.3995, Val Loss: 1.1074\n",
      "INFO:__main__:Epoch 36/50:\n",
      "INFO:__main__:Train Loss: 0.3449, Val Loss: 1.2542\n",
      "INFO:__main__:Epoch 37/50:\n",
      "INFO:__main__:Train Loss: 0.3774, Val Loss: 1.0725\n",
      "INFO:__main__:Epoch 38/50:\n",
      "INFO:__main__:Train Loss: 0.3747, Val Loss: 1.0496\n",
      "INFO:__main__:Epoch 39/50:\n",
      "INFO:__main__:Train Loss: 0.2874, Val Loss: 1.1483\n",
      "INFO:__main__:Epoch 40/50:\n",
      "INFO:__main__:Train Loss: 0.2811, Val Loss: 1.2326\n",
      "INFO:__main__:Epoch 41/50:\n",
      "INFO:__main__:Train Loss: 0.2676, Val Loss: 1.2578\n",
      "INFO:__main__:Epoch 42/50:\n",
      "INFO:__main__:Train Loss: 0.2669, Val Loss: 1.2193\n",
      "INFO:__main__:Epoch 43/50:\n",
      "INFO:__main__:Train Loss: 0.2836, Val Loss: 1.1996\n",
      "INFO:__main__:Epoch 44/50:\n",
      "INFO:__main__:Train Loss: 0.2676, Val Loss: 1.2381\n",
      "INFO:__main__:Epoch 45/50:\n",
      "INFO:__main__:Train Loss: 0.2084, Val Loss: 1.4306\n",
      "INFO:__main__:Epoch 46/50:\n",
      "INFO:__main__:Train Loss: 0.2164, Val Loss: 1.4461\n",
      "INFO:__main__:Epoch 47/50:\n",
      "INFO:__main__:Train Loss: 0.2665, Val Loss: 1.4068\n",
      "INFO:__main__:Epoch 48/50:\n",
      "INFO:__main__:Train Loss: 0.2849, Val Loss: 1.3952\n",
      "INFO:__main__:Epoch 49/50:\n",
      "INFO:__main__:Train Loss: 0.1770, Val Loss: 1.4398\n",
      "INFO:__main__:Epoch 50/50:\n",
      "INFO:__main__:Train Loss: 0.2093, Val Loss: 1.5217\n",
      "INFO:__main__:Test Metrics:\n",
      "INFO:__main__:Accuracy: 0.5100\n",
      "INFO:__main__:Precision: 0.5802\n",
      "INFO:__main__:Recall: 0.4234\n",
      "INFO:__main__:F1 Score: 0.4896\n",
      "INFO:__main__:Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Main function to tie everything together\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    SEQUENCE_LENGTH = 1000\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    # This is a placeholder - replace with actual data loading\n",
    "    signals = np.random.randn(1000, SEQUENCE_LENGTH)  # Replace with real data\n",
    "    labels = np.random.randint(0, 2, (1000, 1))      # Replace with real labels\n",
    "    \n",
    "    # Split data\n",
    "    train_signals, test_signals, train_labels, test_labels = train_test_split(\n",
    "        signals, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    train_signals, val_signals, train_labels, val_labels = train_test_split(\n",
    "        train_signals, train_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MoonquakeDataset(train_signals, train_labels)\n",
    "    val_dataset = MoonquakeDataset(val_signals, val_labels)\n",
    "    test_dataset = MoonquakeDataset(test_signals, test_labels)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Initialize model, criterion, and optimizer\n",
    "    model = InceptionLSTMMoonquake(sequence_length=SEQUENCE_LENGTH).to(DEVICE)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Train model\n",
    "    best_model_state = train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, DEVICE)\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_state_dict(best_model_state)\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, test_loader, DEVICE)\n",
    "    \n",
    "    logger.info(f'Test Metrics:')\n",
    "    logger.info(f'Accuracy: {accuracy:.4f}')\n",
    "    logger.info(f'Precision: {precision:.4f}')\n",
    "    logger.info(f'Recall: {recall:.4f}')\n",
    "    logger.info(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "    # Save model for deployment\n",
    "    torch.save(model.state_dict(), 'moonquake_detector.pth')\n",
    "    logger.info('Model saved successfully')\n",
    "\n",
    "# Function for deployment on satellite\n",
    "def satellite_inference(signal):\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = InceptionLSTMMoonquake().to(DEVICE)\n",
    "    model.load_state_dict(torch.load('moonquake_detector.pth'))\n",
    "    \n",
    "    is_quake = inference(model, signal, DEVICE)\n",
    "    return is_quake\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
